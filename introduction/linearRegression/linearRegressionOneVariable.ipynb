{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression with One Variable\n",
    "\n",
    "We are going to begin this class using an example about the prices of some houses in Portland. We are using information as you know, based on Coursera and Standford Course of Machine Learning. So, let's take a look to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import axes3d # To build the surface plots\n",
    "from matplotlib import cm # To use the colormap\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np.set_printoptions(suppress=True) # This command is used to avoid the scientific output\n",
    "\n",
    "## Let's import the data. We have this dataset into data folder\n",
    "data = np.loadtxt('./data/dataHouses.csv', dtype=np.float64,delimiter=',')\n",
    "print(data[:4,::]) # See the first 4 rows of our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have our data in the **data** variable of our python code. The idea is like our first step create a figure and plot all the information.\n",
    "\n",
    "Our information, as you can see, have two columns, the first column is the size of the house, the second is the price of the house. Let's make the figure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,0]\n",
    "Y = data[:,1]\n",
    "\n",
    "plt.figure()\n",
    "plt.title('House Prices in Portland', fontsize=20)\n",
    "plt.xlabel('Size of House', fontsize=15)\n",
    "plt.ylabel('Price', fontsize=15)\n",
    "plt.scatter(X,Y,color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Representation\n",
    "\n",
    "To establish notation for future use, we'll use $x^{(i)}$ to denote the *input* variables (in this case the size of the House), sometimes you could call it input features, and $y^{(i)}$ to denote the *output* or target variable that we are trying to predict (in this case the price). A pair $(x^{(i)},y^{(i)})$ is called a training example, and the dataset that we'll be using to learn --a list of $m$ training examples $(x^{(i)},y^{(i)})$; $i=1,2,3,...,m$-- is called a training set. Note that the superscript **i** in the notation is simply an index into the training set, and has nothing to do with exponentiation. We will also use $X$ to denote the space of input values, and $Y$ to denote the space of output values. In this example, $X=Y=R$.\n",
    "\n",
    "![Linear Regression](./images/linearRegression.png)\n",
    "\n",
    "We need to obtain a line, as you see in the image above, it needs to approximate in the best way possible our data. That's why we use **Linear Regression** as the name.\n",
    "\n",
    "To describe the supervised learning problem slightly more formally, our goal is, given a training set, to learn a function $h : X → Y$ so that $h(x)$ is a *good* predictor for the corresponding value of $y$. For historical reasons, this function $h$ is called a *hypothesis*. Seen pictorially, the process is therefore like this:\n",
    "\n",
    "![Hypothesis](./images/hypothesis.png)\n",
    "\n",
    "When the target variable that we’re trying to predict is continuous, such as in our housing example, we call the learning problem a regression problem. When $y$ can take on only a small number of discrete values (such as if, given the living area, we wanted to predict if a dwelling is a house or an apartment, say), we call it a classification problem.\n",
    "\n",
    "## Cost Function\n",
    "\n",
    "To create our **Cost Function** we need to define some kind of *hypothesis* function to try to predict the output values of our *model*. Taking into account that our problem is a *Linear Problem* the idea is to use this representation to build our function *hypothesis*.\n",
    "\n",
    "### Hypothesis: $h_{\\theta}(x) = \\theta_{0} + \\theta_{1}x$\n",
    "\n",
    "### Parameters: $\\theta_{i}$\n",
    "\n",
    "So, our *hypothesis* function is already defined, but we need to choose $\\theta_{0}$ and $\\theta_{1}$ in some way that our predicted values stay close to the values defined by the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0,50,5)\n",
    "\n",
    "y = 1.5 + 0*x\n",
    "plt.figure(figsize = (15,4),dpi=100)\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(x,y)\n",
    "plt.title('h(x)=1.5+0x')\n",
    "plt.ylim(0,23)\n",
    "\n",
    "y = 0 + 0.5*x\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(x,y)\n",
    "plt.title('h(x)=0.5x')\n",
    "plt.ylim(0,23)\n",
    "\n",
    "y = 1.0 + 0.5*x\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(x,y)\n",
    "plt.title('h(x)=1+0.5x')\n",
    "plt.ylim(0,24);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, you could start to give values and try to discover if you have a good approximation to the data. However this would be a very complicated task. The idea is to measure, for each value of the $\\theta$, how close the $h_{\\theta}(x^{(i)})$ are to the corresponding $y^{(i)}$. So the **Cost Function** is defined by:\n",
    "\n",
    "$$J(\\theta)=\\frac{1}{2m}\\sum_{i=1}^{m}(h_{\\theta}(x^{(i)})-y^{(i)})^{2}$$\n",
    "\n",
    "The function above is called the *Squared error function*, or *Mean squared error*. The mean is halved $\\frac{1}{2}$ as a convenience for the computation of the gradient descent, as the derivative term of the square function will cancel out the $\\frac{1}{2}$ term. The idea is to minimize $J(\\theta)$, to obtain the best $\\theta$ to approximate the data set.\n",
    "\n",
    "Ok, let's try to discover an algorithm to minimize the **Cost Function** $J(\\theta)$. First let's go back and we will rewrite we've we seen before:\n",
    "\n",
    "### Hypothesis: $h_{\\theta}(x) = \\theta_{0} + \\theta_{1}x$\n",
    "\n",
    "### Parameters: $\\theta_{0},\\theta_{1}$\n",
    "\n",
    "### Cost Function: $J(\\theta_{0},\\theta_{1})=\\frac{1}{2m}\\sum_{i=1}^{m}(h_{\\theta}(x^{(i)})-y^{(i)})^{2}$\n",
    "\n",
    "### Goal: $minimize_{\\theta_{0},\\theta_{1}} J(\\theta_{0},\\theta_{1})$\n",
    "\n",
    "Now we are going to make the things easier, and we will create a simplified version of our problem, let's take a look:\n",
    "\n",
    "### Hypothesis: $h_{\\theta}(x) = \\theta_{1}x$\n",
    "\n",
    "### Parameters: $\\theta_{1}$\n",
    "\n",
    "### Cost Function: $J(\\theta_{1})=\\frac{1}{2m}\\sum_{i=1}^{m}(h_{\\theta}(x^{(i)})-y^{(i)})^{2}$\n",
    "\n",
    "### Goal: $minimize_{\\theta_{1}} J(\\theta_{1})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0,4.0,0.5)\n",
    "\n",
    "x1 = np.arange(1,4,1)\n",
    "\n",
    "# if theta1 is fixed, this is a function of x\n",
    "# if theta1 is equal to 1\n",
    "theta1 = 1\n",
    "y = theta1*x\n",
    "y1 = theta1*x1\n",
    "plt.figure(figsize = (15,4),dpi=100)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(x,y)\n",
    "plt.scatter(x1,y1,color='red',marker='x')\n",
    "plt.title('h(x)=1.0*x')\n",
    "plt.xlabel('x', fontsize=15)\n",
    "plt.ylabel('y', fontsize=15)\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter(1,0,color='green',marker='x')\n",
    "plt.title('J(theta)')\n",
    "plt.ylim(0,2)\n",
    "plt.xlabel('theta1', fontsize=15)\n",
    "plt.ylabel('J(theta)', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows the ideal situation where we have a cost function of 0. When we select $\\theta_{1} = 1$, we get a slope of $1$ which goes through every single data point in our model. Conversely when $\\theta_{1} = 0.5$, we see the vertical distance from our model to the data points increase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0,4.0,0.5)\n",
    "\n",
    "x1 = np.arange(1,4,1)\n",
    "\n",
    "# if theta1 is fixed, this is a function of x\n",
    "# if theta1 is equal to 1\n",
    "theta1 = 0.5\n",
    "y = theta1*x\n",
    "y1 = 1*x1\n",
    "plt.figure(figsize = (15,4),dpi=100)\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(x,y)\n",
    "plt.scatter(x1,y1,color='red',marker='x')\n",
    "plt.title('h(x)=1.0*x')\n",
    "plt.xlabel('x', fontsize=15)\n",
    "plt.ylabel('y', fontsize=15)\n",
    "\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.scatter([1,0.5],[0,0.5],color='green',marker='x')\n",
    "plt.title('J(theta)')\n",
    "plt.ylim(0,2)\n",
    "plt.xlim(-0.5,3.0)\n",
    "plt.xlabel('theta1', fontsize=15)\n",
    "plt.ylabel('J(theta)', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the plot of $J(\\theta)$, shows two points, one of them is when theta1 is equal to 1. In this case the Cost Function is equal to zero. If you choose $\\theta_{1} = 0.5$ then $J(\\theta) = 0.58333333$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1, 2, 3]) # Input Variables\n",
    "y = np.array([1, 2, 3]) # Target Variables\n",
    "m = x.shape[0] # Number of Variables. x,y are known as training example\n",
    "theta1 = np.array([1.0,0.5,1.5,2,2.5,0,-0.5,-1.0,3.0]) # One of the parameters of our hypothesis\n",
    "J = np.zeros(theta1.shape[0])\n",
    "j = 0\n",
    "for i in theta1:\n",
    "    h_theta = i*x\n",
    "    J[j] = (1/(2*m)) * (np.sum(np.square(h_theta - y))) # Cost function to minimize\n",
    "    j = j + 1\n",
    "plt.scatter(theta1,J,color='green',marker='x')\n",
    "plt.title('J(theta)')\n",
    "plt.xlabel('theta1', fontsize=15)\n",
    "plt.ylabel('J(theta)', fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is clear that the answer to our simplified version of the Cost Function is $\\theta_{1} = 1$, this is our global minimum as you can see in the figure above.\n",
    "\n",
    "Now, in general terms, our model is:\n",
    "\n",
    "### Hypothesis: $h_{\\theta}(x) = \\theta_{0} + \\theta_{1}x$\n",
    "\n",
    "### Parameters: $\\theta_{0},\\theta_{1}$\n",
    "\n",
    "### Cost Function: $J(\\theta_{0},\\theta_{1})=\\frac{1}{2m}\\sum_{i=1}^{m}(h_{\\theta}(x^{(i)})-y^{(i)})^{2}$\n",
    "\n",
    "### Goal: $minimize_{\\theta_{0},\\theta_{1}} J(\\theta_{0},\\theta_{1})$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_0 = 50000\n",
    "theta_1 = 60\n",
    "h_theta = theta_0 + theta_1*X # Our hypothesis\n",
    "\n",
    "plt.figure()\n",
    "plt.title('h_theta(x), theta_0=50000 and theta_1=60', fontsize=15)\n",
    "plt.xlabel('Size of House', fontsize=15)\n",
    "plt.ylabel('Price', fontsize=15)\n",
    "plt.scatter(X,Y,color='red',marker='x')\n",
    "plt.plot(X,h_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see in the figure above our hypothesis isn't very good. If we have $\\theta_{0}$ and $\\theta_{1}$ fixed you obtain a function of $x$. In the figure the hypothesis is defined as $h_{\\theta}(x) = 50000 + 60x$. But you can make some contour plots to see how is the $J(\\theta_{0},\\theta_{1})$ and try to find the optimum value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = X.shape[0] # Number of Variables. x,y are known as training example\n",
    "theta1 = np.linspace(-60,200,500)\n",
    "theta0 = np.linspace(-50000,500000,500)\n",
    "J = np.zeros(theta1.shape[0])\n",
    "j = 0\n",
    "for i in theta1:\n",
    "    h_theta = theta0[j]+i*X\n",
    "    J[j] = (1/(2*m)) * (np.sum(np.square(h_theta - Y))) # Cost function to minimize\n",
    "    j = j + 1\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.add_subplot(121)\n",
    "plt.plot(theta0,J)\n",
    "fig.add_subplot(122)\n",
    "plt.plot(theta1,J)\n",
    "plt.show()\n",
    "\n",
    "## It is important to create a surface plot of this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "Now, we know how to try to obtain a Linear equation to follow all the data. However our optimization problem works only in a very handmade manner. So, we need to stablish a proper way to solve this with a computational algorithm.\n",
    "\n",
    "Suppose that you are going to plot only the hypothesis function. In order to find the minimum of this function you could find in a graphical way the approximations to $\\theta_{0}$ and $\\theta_{1}$.\n",
    "\n",
    "In the cell code below you will find an example of a test function to understand this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Grab some test data.\n",
    "X, Y, Z = axes3d.get_test_data(0.2)\n",
    "# Plot a basic surface\n",
    "surf = ax.plot_surface(X, Y, Z, rstride=10, cstride=10, cmap=cm.coolwarm_r)\n",
    "plt.xlabel('theta0', fontsize=15)\n",
    "plt.ylabel('theta1', fontsize=15)\n",
    "plt.title('J(theta0,theta1)', fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the blue arrow shows the minimum value. You could find this minimum value through the use of the derivative of our cost function. The slope of the tangent is the derivative at that point and it will give us a direction to move towards. We make steps down the cost function in the direction with the steepest descent. The size of each step is controlled by a parameter called $\\alpha$ or **learning rate**.\n",
    "\n",
    "The direction of each step is determined by the partial derivative of $J(\\theta_{0},\\theta_{1})$. You could choose different inital values and finish with different points.\n",
    "\n",
    "![Minimum](./images/GDPlot.png)\n",
    "\n",
    "The **Gradient Descent** algorithm is:\n",
    "\n",
    "$$\\theta_{j} := \\theta_{j} - \\alpha \\frac{\\partial}{\\partial \\theta_{j}} J(\\theta_{0},\\theta_{1})$$\n",
    "\n",
    "Where $j=0,1$ represents the feature index number. In our example it refers to $\\theta_{0}$ and $\\theta_{1}$\n",
    "\n",
    "At each iteration $j$, you need to do the update simultaneously for each $\\theta_{0},\\theta_{1},\\theta_{2},...,\\theta_{n}$. Updating a specific parameter prior to calculating another one on the $\\theta^{(th)}$ iteration would yield to a wrong implementation:\n",
    "\n",
    "$$\\begin{equation}\n",
    "    \\begin{split}\n",
    "        \\theta_{t0} := \\theta_{0} \\alpha \\frac{\\partial}{\\partial \\theta_{0}} J(\\theta_{0},\\theta_{1}) \\\\\n",
    "        \\theta_{t1} := \\theta_{1} \\alpha \\frac{\\partial}{\\partial \\theta_{1}} J(\\theta_{0},\\theta_{1}) \\\\ \n",
    "        \\theta_{0} := \\theta_{t0} \\\\\n",
    "        \\theta_{1} := \\theta_{t1}\n",
    "    \\end{split}\n",
    "\\end{equation}$$\n",
    "\n",
    "Rewriting the Algorihtm you obtain something like this:\n",
    "\n",
    "*Repeat until convergence and simultaneously update $j=0$ and $j=1$:*\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\theta_{j} := \\theta_{j} - \\alpha \\frac{\\partial}{\\partial \\theta_{j}} J(\\theta_{0},\\theta_{1})\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "The **Learning Rate** parameter, as you can think, is used to adjust the convergence speed of our implementation. However it is important to choose a right **Learning Rate**:\n",
    "\n",
    "![Learning Rate](./images/learningRate.png)\n",
    "\n",
    "We should adjust our paramater $\\alpha$ to ensure that the gradient descent algorithm converges in a reasonable time. Failure to converge or too much time to obtain the minimum value imply that our step size is wrong.\n",
    "\n",
    "![Learning Rate](./images/learningRate2.png)\n",
    "\n",
    "The **Gradient Descent** algorithm  does not always converge to a global optima. In some cases it can converge to a local optima.\n",
    "\n",
    "![Learning Rate](./images/learningRate4.png)\n",
    "\n",
    "\n",
    "![Learning Rate](./images/learningRate3.png)\n",
    "\n",
    "## Gradient Descent for Linear Regression\n",
    "\n",
    "![Linear Regression GD](./images/GDLinearRegression.png)\n",
    "\n",
    "![Linear Regression GD](./images/GDLinearRegression2.png)\n",
    "\n",
    "![Linear Regression GD](./images/GDLinearRegression3.png)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
